#!/usr/bin/env node
/**
 * Neural Benchmark Visualization
 * Creates visual representations of benchmark results
 */

const fs = require('fs').promises;
const path = require('path');

class BenchmarkVisualizer {
    constructor() {
        this.benchmarkData = null;
    }

    async loadBenchmarkData() {
        const benchmarkPath = path.join(process.cwd(), '.ruv-swarm', 'benchmarks', 'neural-benchmark-1751398753060.json');
        this.benchmarkData = JSON.parse(await fs.readFile(benchmarkPath, 'utf8'));
    }

    generateASCIIChart(data, title, maxWidth = 60) {
        console.log(`\n${title}`);
        console.log('=' .repeat(maxWidth));
        
        const maxValue = Math.max(...Object.values(data));
        
        Object.entries(data).forEach(([label, value]) => {
            const barLength = Math.floor((value / maxValue) * (maxWidth - 20));
            const bar = '‚ñà'.repeat(barLength);
            const percentage = ((value / maxValue) * 100).toFixed(1);
            console.log(`${label.padEnd(12)} ${bar} ${value} (${percentage}%)`);
        });
    }

    visualizeResults() {
        console.log('\nüß† NEURAL MODEL BENCHMARK VISUALIZATION');
        console.log('=' .repeat(70));
        console.log(`üìÖ Benchmark Date: ${this.benchmarkData.timestamp}`);
        console.log(`‚è±Ô∏è  Total Duration: ${(this.benchmarkData.duration / 1000).toFixed(2)} seconds`);

        // Accuracy Comparison
        const accuracyData = {};
        Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
            accuracyData[model.toUpperCase()] = parseFloat(data.architecture.accuracy);
        });
        this.generateASCIIChart(accuracyData, 'üéØ MODEL ACCURACY COMPARISON (%)', 70);

        // Inference Speed Comparison
        const speedData = {};
        Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
            speedData[model.toUpperCase()] = Math.floor(data.inference.mean);
        });
        this.generateASCIIChart(speedData, '‚ö° INFERENCE SPEED (ops/sec)', 70);

        // Memory Usage Comparison
        const memoryData = {};
        Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
            memoryData[model.toUpperCase()] = data.memory.totalMemory;
        });
        this.generateASCIIChart(memoryData, 'üíæ MEMORY USAGE (MB)', 70);

        // Training Time Comparison
        const trainingData = {};
        Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
            trainingData[model.toUpperCase()] = Math.floor(data.timings.training);
        });
        this.generateASCIIChart(trainingData, '‚è±Ô∏è  TRAINING TIME (ms)', 70);

        // Parameter Count Comparison
        const paramData = {};
        Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
            paramData[model.toUpperCase()] = Math.floor(data.architecture.parameters / 1000);
        });
        this.generateASCIIChart(paramData, 'üî¢ PARAMETERS (thousands)', 70);

        // Performance Matrix
        this.generatePerformanceMatrix();

        // Model Rankings
        this.generateModelRankings();

        // Trade-off Analysis
        this.generateTradeoffAnalysis();
    }

    generatePerformanceMatrix() {
        console.log('\nüìä PERFORMANCE MATRIX');
        console.log('=' .repeat(70));
        console.log('Model        | Accuracy | Speed    | Memory  | Training | Parameters');
        console.log('-------------|----------|----------|---------|----------|------------');

        Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
            const row = [
                model.toUpperCase().padEnd(12),
                `${data.architecture.accuracy}%`.padEnd(9),
                `${Math.floor(data.inference.mean)} ops/s`.padEnd(9),
                `${data.memory.totalMemory} MB`.padEnd(8),
                `${(data.timings.training / 1000).toFixed(2)}s`.padEnd(9),
                `${(data.architecture.parameters / 1000).toFixed(0)}K`
            ];
            console.log(row.join(' | '));
        });
    }

    generateModelRankings() {
        console.log('\nüèÜ MODEL RANKINGS BY METRIC');
        console.log('=' .repeat(70));

        // Rank by different metrics
        const metrics = [
            { name: 'Accuracy', key: 'architecture.accuracy', higher: true, unit: '%' },
            { name: 'Inference Speed', key: 'inference.mean', higher: true, unit: ' ops/s' },
            { name: 'Memory Efficiency', key: 'memory.efficiency', higher: true, unit: '%' },
            { name: 'Training Speed', key: 'timings.training', higher: false, unit: 'ms' },
            { name: 'Parameter Efficiency', key: 'architecture.parameters', higher: false, unit: '' }
        ];

        metrics.forEach(metric => {
            console.log(`\n${metric.name}:`);
            const ranked = Object.entries(this.benchmarkData.results)
                .map(([model, data]) => {
                    const value = metric.key.split('.').reduce((obj, key) => obj[key], data);
                    return { model, value };
                })
                .sort((a, b) => metric.higher ? b.value - a.value : a.value - b.value);

            ranked.forEach((item, index) => {
                const medal = index === 0 ? 'ü•á' : index === 1 ? 'ü•à' : index === 2 ? 'ü•â' : '  ';
                const value = metric.unit === '%' ? parseFloat(item.value).toFixed(1) : 
                             Math.floor(item.value);
                console.log(`  ${medal} ${(index + 1)}. ${item.model.toUpperCase()}: ${value}${metric.unit}`);
            });
        });
    }

    generateTradeoffAnalysis() {
        console.log('\n‚öñÔ∏è  TRADE-OFF ANALYSIS');
        console.log('=' .repeat(70));

        const models = Object.entries(this.benchmarkData.results).map(([name, data]) => ({
            name: name.toUpperCase(),
            accuracy: parseFloat(data.architecture.accuracy),
            speed: data.inference.mean,
            memory: data.memory.totalMemory,
            efficiency: data.memory.efficiency
        }));

        console.log('\nüìà Accuracy vs Speed Trade-off:');
        models.sort((a, b) => (b.accuracy * b.speed) - (a.accuracy * a.speed))
            .forEach(model => {
                const score = (model.accuracy * model.speed / 100).toFixed(1);
                console.log(`  ${model.name}: ${score} (${model.accuracy}% √ó ${Math.floor(model.speed)} ops/s)`);
            });

        console.log('\nüíæ Memory vs Performance Trade-off:');
        models.sort((a, b) => (b.accuracy / b.memory) - (a.accuracy / a.memory))
            .forEach(model => {
                const score = (model.accuracy / model.memory * 1000).toFixed(2);
                console.log(`  ${model.name}: ${score} (${model.accuracy}% / ${model.memory}MB)`);
            });

        console.log('\n‚ö° Overall Efficiency Score:');
        models.forEach(model => {
            // Normalize values (0-1 scale)
            const normAccuracy = model.accuracy / 100;
            const normSpeed = model.speed / 350; // Max speed ~350
            const normMemEff = 1 - (model.memory / 6000); // Inverse, lower is better
            const overallScore = ((normAccuracy * 0.4) + (normSpeed * 0.3) + (normMemEff * 0.3)) * 100;
            
            model.overallScore = overallScore;
        });

        models.sort((a, b) => b.overallScore - a.overallScore)
            .forEach((model, index) => {
                const medal = index === 0 ? 'üèÜ' : '';
                console.log(`  ${medal} ${model.name}: ${model.overallScore.toFixed(1)}/100`);
            });
    }

    async visualize() {
        try {
            await this.loadBenchmarkData();
            this.visualizeResults();
            
            console.log('\n\nüí° KEY INSIGHTS:');
            console.log('=' .repeat(70));
            console.log('‚Ä¢ Attention model achieves best accuracy (94.31%) with good memory efficiency');
            console.log('‚Ä¢ Feedforward offers 3x faster inference than any other model');
            console.log('‚Ä¢ Transformer provides best balance for parallel workloads');
            console.log('‚Ä¢ LSTM remains optimal for sequential data despite lower overall scores');
            console.log('\n‚úÖ Visualization complete!');
        } catch (error) {
            console.error('‚ùå Error:', error.message);
        }
    }
}

// Run visualization
const visualizer = new BenchmarkVisualizer();
visualizer.visualize();